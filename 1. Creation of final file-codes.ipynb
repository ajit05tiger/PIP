{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451a85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9db1ab",
   "metadata": {},
   "source": [
    "## 1. Renaming files with it's activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"D:/Ajit/pip/sample_labeled\"\n",
    "folder_list = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    folder_list.append(subdir)\n",
    "del folder_list[0]\n",
    "folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folder_list:\n",
    "    path=folder\n",
    "    i=0\n",
    "    ne=0\n",
    "    ur=0\n",
    "    df=0\n",
    "    for filename in os.listdir(path):\n",
    "    #     print(path+'/'+filename)\n",
    "        x=path+'/'+filename\n",
    "    #     print(x)\n",
    "        if i%2!=0:\n",
    "            tag=''\n",
    "            df_json=pd.read_json(x,lines=True)\n",
    "            activities = ['non_elimination', 'urination', 'defecation']\n",
    "            for val in df_json['Tags'][0]:\n",
    "                if val in activities:\n",
    "                    tag=val\n",
    "                    if tag=='non_elimination':\n",
    "                        ne+=1\n",
    "                        new_name =tag +str(ne)+ \".csv\"\n",
    "                        my_source =x.replace('json','csv')\n",
    "                        my_dest =path +('/')+ new_name\n",
    "                        os.rename(my_source, my_dest)\n",
    "\n",
    "                        new_name_json = tag +str(ne)+ \".json\"\n",
    "                        my_source_json = x\n",
    "                        print(my_source_json)\n",
    "                        my_dest_json = path +('/')+ new_name_json\n",
    "                        os.rename(my_source_json, my_dest_json)        \n",
    "\n",
    "\n",
    "                    elif tag=='urination':\n",
    "                        ur+=1\n",
    "                        new_name =tag +str(ur)+ \".csv\"\n",
    "                        my_source =x.replace('json','csv')\n",
    "                        my_dest =path +('/')+ new_name\n",
    "                        os.rename(my_source, my_dest)\n",
    "\n",
    "                        new_name_json = tag +str(ur)+ \".json\"\n",
    "                        my_source_json = x\n",
    "                        print(my_source_json)\n",
    "                        my_dest_json = path +('/')+ new_name_json\n",
    "                        os.rename(my_source_json, my_dest_json)\n",
    "\n",
    "                    else:\n",
    "                        df+=1\n",
    "                        new_name =tag +str(df)+ \".csv\"\n",
    "                        my_source =x.replace('json','csv')\n",
    "                        my_dest =path +('/')+ new_name\n",
    "                        os.rename(my_source, my_dest)\n",
    "\n",
    "                        new_name_json = tag +str(df)+ \".json\"\n",
    "                        my_source_json = x\n",
    "                        print(my_source_json)\n",
    "                        my_dest_json = path +('/')+ new_name_json\n",
    "                        os.rename(my_source_json, my_dest_json)                  \n",
    "\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            print(i)\n",
    "            i+=1\n",
    "\n",
    "        else:\n",
    "            i+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ea8a6",
   "metadata": {},
   "source": [
    "## 2. Creation of new csv files with outlier Treatment and all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49263c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "rootdir = \"D:/Ajit/pip/sample_labeled/\"\n",
    "folder_list = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    folder_list.append(subdir)\n",
    "del folder_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfba7e",
   "metadata": {},
   "source": [
    "### i. Creating empty folder with folder numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9de786",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in folder_list:\n",
    "    path=path.replace('sample_labeled','sample_labeled8')\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281332e",
   "metadata": {},
   "source": [
    "### ii. Outlier treatment with flooring & capping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd450887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_capping(col_name):\n",
    "    Q1 = 0\n",
    "    Q3 = df[col_name].quantile(0.98)\n",
    "    IQR = Q3\n",
    "     \n",
    "    upper_bound = Q3 + 3.5 * IQR   # Whisker width is 4\n",
    "    no_upper_outlier=len(df[df[col_name]>upper_bound])\n",
    "    print(\"number of outlier: \"+str(no_upper_outlier))\n",
    "    df[col_name]=np.where(df[col_name]>upper_bound,upper_bound,df[col_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed9663",
   "metadata": {},
   "source": [
    "### iii. creating new csv files in created folders with outlier treatment and new features:\n",
    "#### 1.Differential load\n",
    "#### 2. Sum of absolute value of differential load\n",
    "#### 3. Acceleration\n",
    "#### 4. Velocity\n",
    "#### 5. Energy\n",
    "#### 6. Power\n",
    "#### 7. Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folder_list:\n",
    "    path=folder\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        x=path+'/'+filename\n",
    "        if filename.endswith(\".csv\"):\n",
    "            print(x)\n",
    "            df=pd.read_csv(x)\n",
    "            df_json=pd.read_json(x.replace('csv','json'),lines=True)\n",
    "\n",
    "            df['name'] = df_json['Name_of_cat'][0]\n",
    "            df['weight'] = df_json['Weight_of_cat'][0]\n",
    "            activities = ['non_elimination', 'urination', 'defecation']\n",
    "            tag=\"\"\n",
    "            for val in df_json['Tags'][0]:\n",
    "                if val in activities:\n",
    "                    tag=val\n",
    "\n",
    "            df['activity']=tag\n",
    "\n",
    "# difference of load from it's previous load (incremental or decremental load) and converted to abslolute value\n",
    "            df['diff_lc0']= df['lc0'].diff().abs()\n",
    "            df['diff_lc1']= df['lc1'].diff().abs()\n",
    "            df['diff_lc2']= df['lc2'].diff().abs()\n",
    "            df['diff_lc3']= df['lc3'].diff().abs()\n",
    "            \n",
    "# sum of all the loads as in aggregated datasheet all the load sensor's are corelated so we will work with only sum of all load sensor's differential value\n",
    "            df['diff_load_sum']= df['diff_lc0']+df['diff_lc1']+df['diff_lc2']+df['diff_lc3']\n",
    "            \n",
    "# Outlier treatment with Q1=0 (because all differential valus are converted to absolute), Q3=0.98 quantile and whisker width = 3.5 and \n",
    "            outlier_capping('diff_load_sum')\n",
    "\n",
    "# w = Weight of cat \n",
    "            w = df_json['Weight_of_cat'][0]\n",
    "    \n",
    "## Force = Mass * Acceleration\n",
    "## Acceleration (a) = Force / Weight of cat (w)\n",
    "            df['acc']= df['diff_load_sum'].apply(lambda x: x/w)\n",
    "\n",
    "## Velocity, v2 = (a1*t) + v1\n",
    "            df['velo'] = 0\n",
    "            for i in range (1,len(df)):\n",
    "                df['velo'][i]=(df['acc'][i]*0.025)+(df['velo'][i-1])\n",
    "\n",
    "## Energy (Kinetic Energy), e = 0.5(w*v**2) \n",
    "            df['enr']= df['velo'].apply(lambda x: 0.5*w*(x**2))\n",
    "\n",
    "## Power = Force * Velocity\n",
    "            df['power']= df['velo']*df['diff_load_sum']\n",
    "\n",
    "## Momentum = Mass * Velocity\n",
    "            df['mom']=w*df['velo']\n",
    "\n",
    "            filename = x\n",
    "            filename=filename.replace('sample_labeled','sample_labeled8')\n",
    "\n",
    "            df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3889f",
   "metadata": {},
   "source": [
    "## 3. Creation of Final csv file:\n",
    "#### Following are the columns:\n",
    "#### 1. Name\n",
    "#### 2. Activity\n",
    "#### 3. Weight\n",
    "#### 4. Duration \n",
    "#### 5. Event time\n",
    "#### 6. Maximum value of \"sum of differential load\"\n",
    "#### 7. mean of \"sum of differential load\"\n",
    "#### 8. mean of Varience\n",
    "#### 9. Skewness\n",
    "#### 10. Kurtosis\n",
    "#### 11. 90th percentile\n",
    "#### 12. Acceleration\n",
    "#### 13. Velocity\n",
    "#### 14. Energy\n",
    "#### 15. Power\n",
    "#### 16. Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.DataFrame(columns = ['name' ,'activity' ,'weight', 'duration','start_time' ,'mean_diff_sum', 'variance',  'maximim', 'median', 'skewness', 'kurtosis', '0.9_quantile', 'acceleration', 'velocity', 'energy', 'power', 'momentum'])\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc67177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_insertion(loc_csv):\n",
    "    df=pd.read_csv(loc_csv)\n",
    "    print(loc_csv)\n",
    "    df_main.loc[len(df_main.index)] = [df['name'][0], df['activity'][0], df['weight'][0], df['timestamp'][len(df)-1], df['start_time'][0], df['diff_load_sum'].mean(), df['diff_load_sum'].var(), df['diff_load_sum'].max(), df['diff_load_sum'].median(), df['diff_load_sum'].skew(), df['diff_load_sum'].kurtosis(), df['diff_load_sum'].quantile(0.9), df['acc'].mean(), df['velo'].mean(), df['enr'].mean(), df['power'].mean(), df['mom'].mean()]\n",
    "    return df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"D:/Ajit/pip/sample_labeled5\"\n",
    "folder_list = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    folder_list.append(subdir)\n",
    "del folder_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for folder in folder_list:\n",
    "    path=folder\n",
    "    for filename in os.listdir(path):\n",
    "        x=path+'/'+filename\n",
    "        print(i)\n",
    "        value_insertion(x)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66941a",
   "metadata": {},
   "source": [
    "## 4. Adding a column in final data sheet if required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = 'C:/Users/ajit.mishra/Downloads/practice/sample/'\n",
    "folder_list = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    folder_list.append(subdir)\n",
    "del folder_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name = input('Enter new column name: ')\n",
    "used_name = input('Enter the name of used column: ')\n",
    "df_main[new_name] = \"\"\n",
    "i=0\n",
    "for loc_folder in folder_list:\n",
    "    os.chdir(loc_folder)\n",
    "    for FileList in glob.glob('*.csv'):\n",
    "        loc_csv=loc_folder+'/'+FileList\n",
    "        print(loc_csv)\n",
    "        df_csv=pd.read_csv(loc_csv)\n",
    "        val = df_csv[used_name].max()\n",
    "        print(val)\n",
    "        df_main.loc[i,new_name]=val\n",
    "        print(i)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f299df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
